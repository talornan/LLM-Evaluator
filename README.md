# LLM Evaluator: Unleash the Potential of Large Language Models

## Project Description
**Why waste precious time on manual evaluation of responses from various large language models?
LLM Evaluator is here to the rescue!**

Our web application automates the entire evaluation process, providing you with deep insights and comparisons between different models and tasks.

### **Here's what LLM Evaluator can do for you:**

**Effortless Evaluation**: Feed your prompts, choose models, and instantly get deep insights and comparisons with key metrics like Fluency, Coherence, and Toxicity. ‚ú®

**Model Matchmaker**: Find the perfect LLM for your task by comparing responses across different models.

**Continuous Improvement**: Track progress over time, identify areas for improvement, and stay ahead of the curve.

**Tailored for Experts**: Whether you're a Prompt Engineer crafting winning prompts or a Model Developer optimizing performance, LLM Evaluator has tools for you.

**In addition to the above, here are some details about the evaluation metrics:**
1. Roughness:ü™® Measures the consistency and correctness of the response.
2. Coherence: Evaluate the logical flow and cohesiveness of the response.
3. Fluency:ü™∂ Assesses the naturalness and smoothness of the response.
4. Toxicity: ‚Äç‚ôÄÔ∏è Detects the presence of harmful or offensive language in the response.

## LLM Evaluator is perfect for:

1. Prompt Engineers:‚ú® Create Prompts, analyze performance, receive recommendations for improving Prompts.‚ú®
2. Model Developers: Analyze model performance, receive recommendations on which model to use for a specific Prompt.

##Technologies:

LLM Evaluator leverages a robust tech stack for seamless evaluation and insightful comparisons:

**Frontend:** HTML, CSS (Built with Streamlit for rapid development)
**Backend:** Python (Fast API for a performant and flexible REST API)
**Machine Learning:** Hugging Face Transformer library for efficient access and interaction with various LLMs
**Database:** MySQL for storing prompts, responses, and evaluation results
API Functionality:

**The REST API empowers interaction with LLM Evaluator:**

**Submit Prompts:** Send your prompts and specify desired LLM models through intuitive API calls.
**Evaluation Results:** Retrieve comprehensive reports including key metrics like Fluency, Coherence, Roughness, and Toxicity (leveraging Hugging Face evaluation functions).
**Model Comparison:** Compare performance across different LLMs for informed decision-making.


**Ready to unleash the full potential of your LLMs?**
**Start your free trial today! ‚ú®** 

## Technologies: 
HTML, CSS, Javascript , Python , MySQL
